# Root logger option
log4j.rootLogger=INFO, file, console, spark, etl, data, analysis

# Direct log messages to console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.Target=System.out
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Direct log messages to a log file
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=${WAREHOUSE_DIR}/logs/nycbs.log
log4j.appender.file.MaxFileSize=100MB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Direct Spark log messages to a separate file
log4j.appender.spark=org.apache.log4j.RollingFileAppender
log4j.appender.spark.File=${WAREHOUSE_DIR}/logs/spark.log
log4j.appender.spark.MaxFileSize=100MB
log4j.appender.spark.MaxBackupIndex=10
log4j.appender.spark.layout=org.apache.log4j.PatternLayout
log4j.appender.spark.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# ETL specific logging
log4j.appender.etl=org.apache.log4j.RollingFileAppender
log4j.appender.etl.File=${WAREHOUSE_DIR}/logs/etl.log
log4j.appender.etl.MaxFileSize=100MB
log4j.appender.etl.MaxBackupIndex=10
log4j.appender.etl.layout=org.apache.log4j.PatternLayout
log4j.appender.etl.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Data specific logging
log4j.appender.data=org.apache.log4j.RollingFileAppender
log4j.appender.data.File=${WAREHOUSE_DIR}/logs/data.log
log4j.appender.data.MaxFileSize=100MB
log4j.appender.data.MaxBackupIndex=10
log4j.appender.data.layout=org.apache.log4j.PatternLayout
log4j.appender.data.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Analysis specific logging
log4j.appender.analysis=org.apache.log4j.RollingFileAppender
log4j.appender.analysis.File=${WAREHOUSE_DIR}/logs/analysis.log
log4j.appender.analysis.MaxFileSize=100MB
log4j.appender.analysis.MaxBackupIndex=10
log4j.appender.analysis.layout=org.apache.log4j.PatternLayout
log4j.appender.analysis.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Spark specific logging
log4j.category.org.apache.spark=INFO, spark
log4j.category.org.spark-project=INFO, spark
log4j.category.org.apache.hadoop=INFO, spark
log4j.category.io.netty=INFO, spark
log4j.category.org.apache.zookeeper=INFO, spark
log4j.category.org.apache.hive=INFO, spark

# Application specific logging
log4j.category.com.nycbs=DEBUG, file, console
log4j.category.com.nycbs.data=DEBUG, data, file, console
log4j.category.com.nycbs.etl=DEBUG, etl, file, console
log4j.category.com.nycbs.analysis=DEBUG, analysis, file, console

# Performance metrics logging
log4j.category.com.nycbs.performance=INFO, file, console
log4j.category.com.nycbs.metrics=INFO, file, console

# Data quality logging
log4j.category.com.nycbs.quality=INFO, data, file, console

# Error and exception logging
log4j.category.com.nycbs.error=ERROR, file, console
log4j.category.com.nycbs.exception=ERROR, file, console

# Suppress verbose logging
log4j.category.org.apache.spark.storage=WARN, spark
log4j.category.org.apache.spark.scheduler=WARN, spark
log4j.category.org.apache.spark.executor=WARN, spark
log4j.category.org.apache.spark.network=WARN, spark
log4j.category.org.apache.spark.shuffle=WARN, spark
log4j.category.org.apache.spark.memory=WARN, spark
log4j.category.org.apache.spark.storage=WARN, spark
log4j.category.org.apache.spark.util=WARN, spark

# ELK Stack specific logging
log4j.category.com.nycbs.elk=INFO, file, console
log4j.category.com.nycbs.logstash=INFO, file, console
log4j.category.com.nycbs.elasticsearch=INFO, file, console

# Log rotation settings
log4j.appender.file.Threshold=INFO
log4j.appender.spark.Threshold=INFO
log4j.appender.etl.Threshold=INFO
log4j.appender.data.Threshold=INFO
log4j.appender.analysis.Threshold=INFO

# Add MDC support for better log correlation
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L [%X{correlationId}] - %m%n
log4j.appender.spark.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L [%X{correlationId}] - %m%n
log4j.appender.etl.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L [%X{correlationId}] - %m%n
log4j.appender.data.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L [%X{correlationId}] - %m%n
log4j.appender.analysis.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L [%X{correlationId}] - %m%n 
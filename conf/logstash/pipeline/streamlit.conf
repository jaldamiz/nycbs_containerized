input {
  # Real-time application logs via TCP
  tcp {
    port => 5000
    codec => json
    type => "application_logs"
  }
  
  # Streamlit logs
  file {
    path => "/var/log/nycbs/streamlit/streamlit.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    type => "streamlit_logs"
  }
  
  # Spark logs
  file {
    path => "/var/log/nycbs/spark/spark.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    type => "spark_logs"
  }
  
  # Delta Lake operation logs
  file {
    path => "/var/log/nycbs/delta/operations.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    type => "delta_logs"
  }
}

filter {
  # Common processing for all logs
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  mutate {
    add_field => {
      "environment" => "production"
      "cluster_name" => "nycbs-cluster"
    }
  }
  
  # Service-specific processing
  if [type] == "streamlit_logs" {
    if [event_category] == "data_load" {
      mutate {
        convert => {
          "duration_ms" => "float"
          "data_size" => "integer"
        }
      }
    }
    
    if [event_category] == "error" {
      mutate {
        add_field => {
          "error_occurred" => true
          "needs_investigation" => true
        }
      }
    }
  }
  
  # Delta Lake specific processing
  if [type] == "delta_logs" {
    if [operation_type] {
      mutate {
        add_field => {
          "data_operation" => true
        }
      }
    }
    
    if [schema_changes] {
      mutate {
        add_field => {
          "schema_evolution" => true
        }
      }
    }
  }
  
  # Performance metrics processing
  if [duration_ms] {
    ruby {
      code => '
        threshold = 1000  # 1 second
        event.set("[performance][is_slow]", event.get("[duration_ms]") > threshold)
      '
    }
  }
  
  # Error severity classification
  if [error_type] {
    ruby {
      code => '
        severity_patterns = {
          /connection|timeout/ => "high",
          /validation|warning/ => "medium",
          /.*/ => "low"
        }
        
        error_type = event.get("[error_type]").to_s.downcase
        severity = "low"
        
        severity_patterns.each do |pattern, level|
          if error_type =~ pattern
            severity = level
            break
          end
        end
        
        event.set("[error_metrics][severity]", severity)
      '
    }
  }
}

output {
  # Main Elasticsearch output
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[type]}-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # Service-specific error logs
  if [error_occurred] == true {
    file {
      path => "/var/log/nycbs/%{[type]}/error/error_%{+YYYY_MM_dd}.log"
      codec => json_lines
    }
  }
  
  # Delta Lake operation logs
  if [type] == "delta_logs" {
    file {
      path => "/var/log/nycbs/delta/history/delta_ops_%{+YYYY_MM_dd}.log"
      codec => json_lines
    }
  }
  
  # Debug output (optional)
  stdout {
    codec => rubydebug
  }
} 
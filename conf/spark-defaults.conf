# Core Spark Configuration
spark.master                              local[*]
spark.driver.memory                       1g
spark.executor.memory                     1g
spark.memory.offHeap.enabled             true
spark.memory.offHeap.size                1g
spark.memory.fraction                     0.8
spark.memory.storageFraction             0.3

# Extensions and Catalogs
spark.sql.extensions                      io.delta.sql.DeltaSparkSessionExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog          org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.jars.packages                      io.delta:delta-core_2.12:2.4.0,io.delta:delta-storage:2.4.0,org.apache.iceberg:iceberg-spark-runtime-3.4_2.12:1.3.1

# Delta Lake Configuration
spark.sql.catalog.delta                   org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.sql.catalog.delta.type             hadoop
spark.sql.catalog.delta.warehouse        /home/aldamiz/warehouse/delta

# Iceberg Configuration
spark.sql.catalog.iceberg                 org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.type           hadoop
spark.sql.catalog.iceberg.warehouse      /home/aldamiz/warehouse/iceberg

# Arrow Configuration
spark.sql.execution.arrow.pyspark.enabled true
spark.sql.execution.arrow.maxRecordsPerBatch 10000
spark.sql.execution.arrow.fallback.enabled true
spark.sql.execution.arrow.pyspark.fallback.enabled true
spark.sql.execution.arrow.pyspark.selfDestruct.enabled true
spark.sql.execution.arrow.pyspark.selfDestruct.maxRecords 200000
spark.sql.execution.arrow.pyspark.selfDestruct.maxMemory 1g
spark.sql.execution.arrow.pyspark.maxRecordsPerBatch 10000
spark.sql.execution.arrow.pyspark.maxRecordsPerFile 1000000

# Performance Tuning
spark.sql.shuffle.partitions              10
spark.default.parallelism                 10
spark.sql.adaptive.enabled                true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.files.maxPartitionBytes        134217728
spark.sql.files.openCostInBytes          134217728

# Warehouse and Event Logging
spark.sql.warehouse.dir                   /home/aldamiz/warehouse
spark.eventLog.enabled                    true
spark.eventLog.dir                        /home/aldamiz/warehouse/eventlogs
spark.history.fs.logDirectory             /home/aldamiz/warehouse/eventlogs
spark.history.fs.cleaner.enabled          true
spark.history.fs.cleaner.interval         1d
spark.history.fs.cleaner.maxAge          7d

# Error Handling and Recovery
spark.task.maxFailures                    4
spark.speculation                         true
spark.speculation.interval                100
spark.speculation.multiplier              1.5
spark.speculation.quantile                0.75

# Network Timeouts
spark.network.timeout                     800s
spark.executor.heartbeatInterval          10s
spark.storage.blockManagerSlaveTimeoutMs  600s

# Delta Lake Optimizations
spark.databricks.delta.properties.defaults.enableChangeDataFeed  true
spark.databricks.delta.properties.defaults.columnMapping.mode    name
spark.databricks.delta.properties.defaults.autoCompact.enabled   true
spark.databricks.delta.properties.defaults.optimizeWrite.enabled true

# Iceberg Optimizations
spark.sql.catalog.iceberg.cache-enabled   true
spark.sql.catalog.iceberg.cache.expiration-interval-ms 3600000
spark.sql.catalog.iceberg.write.format    parquet
spark.sql.catalog.iceberg.write.compression-codec snappy
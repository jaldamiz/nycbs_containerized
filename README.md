# NYC Bike Share Data Analysis

A containerized data analytics platform for NYC Bike Share data using Apache Spark, Delta Lake, and ELK Stack.

## ğŸš€ Features

- **Data Lake Architecture**
  - Landing zone for raw data ingestion
  - Bronze layer for validated data
  - Silver layer for enriched data
  - Gold layer for analytics-ready views

- **Analytics & Visualization**
  - Interactive Streamlit dashboard
  - Jupyter notebooks for analysis
  - Real-time metrics and KPIs
  - Geospatial visualizations

- **Monitoring & Logging**
  - ELK Stack integration (Elasticsearch, Logstash, Kibana)
  - Structured logging with context
  - Performance monitoring
  - Query analytics

## ğŸ—ï¸ Architecture

```
nycbs_containerized/
â”œâ”€â”€ conf/                    # Configuration files
â”‚   â”œâ”€â”€ logstash/           # Logstash pipeline configs
â”‚   â”œâ”€â”€ spark-defaults.conf # Spark configuration
â”‚   â””â”€â”€ log4j.properties   # Logging configuration
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ dashboard/        # Streamlit dashboard
â”‚   â”œâ”€â”€ notebooks/       # Jupyter notebooks
â”‚   â””â”€â”€ utils/          # Shared utilities
â”œâ”€â”€ data/               # Data directories (mounted volumes)
â”‚   â”œâ”€â”€ landing/       # Raw data ingestion
â”‚   â”œâ”€â”€ bronze/        # Validated data
â”‚   â”œâ”€â”€ silver/        # Enriched data
â”‚   â””â”€â”€ gold/          # Analytics views
â””â”€â”€ documentation/     # Project documentation
```

## ğŸ› ï¸ Setup

### Prerequisites
- Docker and Docker Compose
- Git
- 8GB+ RAM recommended

### Quick Start
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/nycbs_containerized.git
   cd nycbs_containerized
   ```

2. Create required Docker volumes:
   ```bash
   docker volume create nycbs_data_landing
   docker volume create nycbs_data_bronze
   docker volume create nycbs_data_silver
   docker volume create nycbs_data_gold
   docker volume create nycbs_warehouse
   ```

3. Start the services:
   ```bash
   docker-compose up -d
   ```

4. Access the services:
   - Jupyter Lab: http://localhost:8888
   - Streamlit Dashboard: http://localhost:8501
   - Kibana: http://localhost:5601

## ğŸ“Š Data Pipeline

1. **Data Ingestion** (`nycbs.ipynb`)
   - Downloads CitiBike trip data
   - Validates file integrity
   - Tracks processing status

2. **Bronze Layer**
   - Raw data preservation
   - Schema enforcement
   - Quality checks

3. **Silver Layer**
   - Data enrichment
   - Feature engineering
   - Time and distance calculations

4. **Gold Layer**
   - Analytics views
   - Aggregated metrics
   - Business KPIs

## ğŸ“ˆ Analytics Dashboard

The Streamlit dashboard (`src/dashboard/app.py`) provides:
- Revenue analysis
- Station utilization
- Temporal patterns
- Route analytics

## ğŸ” Monitoring

- **Logging**: Structured logging with ELK Stack
- **Metrics**: Query performance and data quality
- **Alerts**: Error tracking and notifications

## ğŸ¤ Contributing

1. Follow the directory structure
2. Use provided utilities for logging
3. Maintain data quality checks
4. Document changes and features

## ğŸ“ Best Practices

- Use environment variables for configuration
- Follow the medallion architecture
- Implement proper error handling
- Maintain code documentation

## ğŸ“š Documentation

Detailed documentation available in `/documentation`:
- `architecture.md`: System design and components
- `data.md`: Data model and pipeline
- `logging.md`: Logging and monitoring
- `project_structure.md`: Code organization
- `SERVICE_CATALOG.md`: Service inventory 